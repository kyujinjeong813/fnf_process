{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0      50000000\n1      50000001\n2      50000167\n3      50000168\n4      50000169\n         ...   \n522    50007161\n523    50007162\n524    50007163\n525    50007164\n526    50007165\nName: code, Length: 527, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'C://Users/kyujin/Desktop/PROCESS/code_ìš©í’ˆíŒ€_200715.xlsx'\n",
    "\n",
    "ds_index = pd.read_excel(path, sheet_name='index', index_col=None)\n",
    "ds_index = ds_index[['code', 'category']]\n",
    "\n",
    "ds_index['code'] = ds_index['code'].apply(str)\n",
    "ds_index['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "ds_select = pd.read_excel(path, sheet_name='Sheet1', index_col=None)\n",
    "df_sub = list(ds_select.iloc[:, 2].dropna())\n",
    "df_sub\n",
    "print(len(df_sub))\n",
    "result = list(map(lambda x : ''+str(x).split('.')[0]+'', df_sub))\n",
    "print(len(result))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('C:/Users/kyujin/Desktop/PROCESS/code_ìš©í’ˆíŒ€_200715.xlsx', index_col=None)\n",
    "df = df.iloc[:, 1:4]\n",
    "col = ['depth', 'name', 'code', 'level1', 'level2', 'level3', 'level4']\n",
    "df.reindex(columns=col)\n",
    "\n",
    "df.loc[df['depth']==1, 'level1'] = df.loc[df['depth']==1, 'name']\n",
    "df.loc[df['depth']==2, 'level1'] = df.loc[df['depth']==2, 'name'].map(lambda x : x.split(\">\")[0])\n",
    "df.loc[df['depth']==3, 'level1'] = df.loc[df['depth']==3, 'name'].map(lambda x : x.split(\">\")[0])\n",
    "df.loc[df['depth']==4, 'level1'] = df.loc[df['depth']==4, 'name'].map(lambda x : x.split(\">\")[0])\n",
    "\n",
    "df.loc[df['depth']==2, 'level2'] = df.loc[df['depth']==2, 'name'].map(lambda x : x.split(\">\")[1])\n",
    "df.loc[df['depth']==3, 'level2'] = df.loc[df['depth']==3, 'name'].map(lambda x : x.split(\">\")[1])\n",
    "df.loc[df['depth']==4, 'level2'] = df.loc[df['depth']==4, 'name'].map(lambda x : x.split(\">\")[1])\n",
    "\n",
    "df.loc[df['depth']==3, 'level3'] = df.loc[df['depth']==3, 'name'].map(lambda x : x.split(\">\")[2])\n",
    "df.loc[df['depth']==4, 'level3'] = df.loc[df['depth']==4, 'name'].map(lambda x : x.split(\">\")[2])\n",
    "\n",
    "df.loc[df['depth']==4, 'level4'] = df.loc[df['depth']==4, 'name'].map(lambda x : x.split(\">\")[3])\n",
    "\n",
    "print(df.iloc[:,2:])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           cat_cd_nm    get_date rank  \\\n",
      "0        ìƒì˜ > ë°˜íŒ” í‹°ì…”ì¸   2020-07-03    1   \n",
      "1        ìƒì˜ > ë°˜íŒ” í‹°ì…”ì¸   2020-07-03    2   \n",
      "2        ìƒì˜ > ë°˜íŒ” í‹°ì…”ì¸   2020-07-03    3   \n",
      "3        ìƒì˜ > ë°˜íŒ” í‹°ì…”ì¸   2020-07-03    4   \n",
      "4        ìƒì˜ > ë°˜íŒ” í‹°ì…”ì¸   2020-07-03    5   \n",
      "...              ...         ...  ...   \n",
      "5364  ì•¡ì„¸ì„œë¦¬ > ê¸°íƒ€ ì•¡ì„¸ì„œë¦¬  2020-07-14   16   \n",
      "5365  ì•¡ì„¸ì„œë¦¬ > ê¸°íƒ€ ì•¡ì„¸ì„œë¦¬  2020-07-14   17   \n",
      "5366  ì•¡ì„¸ì„œë¦¬ > ê¸°íƒ€ ì•¡ì„¸ì„œë¦¬  2020-07-14   18   \n",
      "5367  ì•¡ì„¸ì„œë¦¬ > ê¸°íƒ€ ì•¡ì„¸ì„œë¦¬  2020-07-14   19   \n",
      "5368  ì•¡ì„¸ì„œë¦¬ > ê¸°íƒ€ ì•¡ì„¸ì„œë¦¬  2020-07-14   20   \n",
      "\n",
      "                                                   prdt  \\\n",
      "0     í‹°ë– ë¸”ìœ ì—”(TWN) [íŒ¨í‚¤ì§€]ì•„ì´ìŠ¤ë²„ê·¸ ë°˜íŒ” STST3279 + ìŠ¤í”Œë˜ì‰¬ ë°˜íŒ” ST...   \n",
      "1            ì»¤ë²„ë‚«(COVERNAT) S/S AUTHENTIC LOGO TEE WHITE   \n",
      "2                     ì—˜ì— ì”¨(LMC) LMC TWIRLED OG TEE black   \n",
      "3     íŒŒë¥´í‹°ë©˜í† (PARTIMENTO) [íŒ¨í‚¤ì§€][CHUBBY]EMBROIDERY TEE ...   \n",
      "4                    ì—˜ì— ì”¨(LMC) LMC THREE BEARS TEE white   \n",
      "...                                                 ...   \n",
      "5364                      ì•„ì°¨(ACHA) ìŠ¤ì¹´ì¹˜ ë¡œí”„ ë§ê³ ë¦¬ ë°”ì§€ì²´ì¸ _ ì‹¤ë²„   \n",
      "5365           ì•„ì°¨(ACHA) ì¨ì§€ì»¬ìŠ¤í‹¸ í¬ë¡œìŠ¤ ë ˆì´ì–´ë“œ ë°”ì§€ì²´ì¸ _ WHITE(ì‹¤ë²„)   \n",
      "5366                            ì—í”„ì”¨ì— ì— (FCMM) ì˜¬ë¼ìš´ë“œ ë¦¬ìŠ¤íŠ¸ ë°´ë“œ   \n",
      "5367  ì„¸ì´ëª¨ ì˜¨ë„(SAMO ONDOH) 11Â° 34mm Belt Strap - Beige...   \n",
      "5368  ì„¸ì´ëª¨ ì˜¨ë„(SAMO ONDOH) 11Â° 34mm Belt Strap - Croc ...   \n",
      "\n",
      "                                                    url  \\\n",
      "0     https://store.musinsa.com//app/product/detail/...   \n",
      "1     https://store.musinsa.com//app/product/detail/...   \n",
      "2     https://store.musinsa.com//app/product/detail/...   \n",
      "3     https://store.musinsa.com//app/product/detail/...   \n",
      "4     https://store.musinsa.com//app/product/detail/...   \n",
      "...                                                 ...   \n",
      "5364  https://store.musinsa.com//app/product/detail/...   \n",
      "5365  https://store.musinsa.com//app/product/detail/...   \n",
      "5366  https://store.musinsa.com//app/product/detail/...   \n",
      "5367  https://store.musinsa.com//app/product/detail/...   \n",
      "5368  https://store.musinsa.com//app/product/detail/...   \n",
      "\n",
      "                                               prdt_img  \\\n",
      "0     https://image.msscdn.net/images/goods_img/2020...   \n",
      "1     https://image.msscdn.net/images/goods_img/2018...   \n",
      "2     https://image.msscdn.net/images/goods_img/2020...   \n",
      "3     https://image.msscdn.net/images/goods_img/2020...   \n",
      "4     https://image.msscdn.net/images/goods_img/2020...   \n",
      "...                                                 ...   \n",
      "5364  https://image.msscdn.net/images/goods_img/2018...   \n",
      "5365  https://image.msscdn.net/images/goods_img/2018...   \n",
      "5366  https://image.msscdn.net/images/goods_img/2018...   \n",
      "5367  https://image.msscdn.net/images/goods_img/2019...   \n",
      "5368  https://image.msscdn.net/images/goods_img/2019...   \n",
      "\n",
      "                                           prdt_img_url       brand  \\\n",
      "0     //172.0.0.112/mlb/process_team/musinsa_crawl/2...         TWN   \n",
      "1     //172.0.0.112/mlb/process_team/musinsa_crawl/2...    COVERNAT   \n",
      "2     //172.0.0.112/mlb/process_team/musinsa_crawl/2...         LMC   \n",
      "3     //172.0.0.112/mlb/process_team/musinsa_crawl/2...  PARTIMENTO   \n",
      "4     //172.0.0.112/mlb/process_team/musinsa_crawl/2...         LMC   \n",
      "...                                                 ...         ...   \n",
      "5364  //172.0.0.112/mlb/process_team/musinsa_crawl/2...        ACHA   \n",
      "5365  //172.0.0.112/mlb/process_team/musinsa_crawl/2...        ACHA   \n",
      "5366  //172.0.0.112/mlb/process_team/musinsa_crawl/2...        FCMM   \n",
      "5367  //172.0.0.112/mlb/process_team/musinsa_crawl/2...  SAMO ONDOH   \n",
      "5368  //172.0.0.112/mlb/process_team/musinsa_crawl/2...  SAMO ONDOH   \n",
      "\n",
      "                                   prdt_cd   season  ... pg_view acum_sales  \\\n",
      "0                                  1914757  2020S/S  ...   40.8ë§Œ       1.8ë§Œ   \n",
      "1                              C1804SL01WH  2020S/S  ...   29.4ë§Œ         3ë§Œ   \n",
      "2                             20SS_TOTE_BK  2020S/S  ...   23.2ë§Œ       1.4ë§Œ   \n",
      "3     [íŒ¨í‚¤ì§€][CHUBBY]EMBROIDERY TEE (5COLOR)  2020S/S  ...   22.8ë§Œ       1.4ë§Œ   \n",
      "4                             20SS_THBE_WH  2020S/S  ...   27.7ë§Œ       7.7ì²œ   \n",
      "...                                    ...      ...  ...     ...        ...   \n",
      "5364                                  ë°”ì§€ì²´ì¸  2018ALL  ...     200        100   \n",
      "5365                                 ë°”ì§€ì²´ì¸3  2018ALL  ...     200        100   \n",
      "5366                                FC6035     None  ...     400        100   \n",
      "5367                            SMO_B00934  2019ALL  ...      77       None   \n",
      "5368                            SMO_B00935  2019ALL  ...      53       None   \n",
      "\n",
      "        like  review satisfaction origin_price sale_price review_st_date  \\\n",
      "0      7,951   2,050       93.78%       47,800     39,800     2020-05-08   \n",
      "1     21,583  13,801       95.14%       39,000     27,300     2018-04-21   \n",
      "2     13,834   2,225        94.8%       39,000     27,300     2020-04-11   \n",
      "3      7,677   2,081        93.2%       59,800     35,500     2020-05-27   \n",
      "4     12,166   1,656       94.86%       39,000     39,000     2020-04-09   \n",
      "...      ...     ...          ...          ...        ...            ...   \n",
      "5364     192      77       94.54%       17,000     17,000     2018-10-13   \n",
      "5365     215     106       96.98%       25,000     25,000     2018-02-28   \n",
      "5366     131     125       91.04%        6,500      6,500     2018-06-28   \n",
      "5367       3    None         None       42,000     42,000           None   \n",
      "5368       2    None         None       42,000     42,000           None   \n",
      "\n",
      "     most_buy_seg                                           hash_tag  \n",
      "0        25~34 ë‚¨ì„±            {#ì˜¤ë²„í•,#ì˜¤ë²„í•ë°˜íŒ”,#ë°˜íŒ”,#ë°˜íŒ”í‹°ì…”ì¸ ,#íŒ¨í‚¤ì§€,#ê·¸ë˜í”½,#ë°˜íŒ”í‹°}  \n",
      "1        19~24 ë‚¨ì„±                      {#ì»¤ë²„ë‚«,#ë¡œê³ ,#ì˜¤ë²„í•,#ë°˜íŒ”,#ë°˜íŒ”í‹°,#ë¡œê³ í‹°}  \n",
      "2        19~24 ë‚¨ì„±              {\"#LMC ë°˜íŒ”\",\"#ì—˜ì— ì”¨ íŠ¸ìœŒ OG í‹°ì…”ì¸ \",#ë¡œê³ ,#LMC}  \n",
      "3        25~34 ë‚¨ì„±       {#ì²˜ë¹„,#ë°˜íŒ”,#í‹°ì…”ì¸ ,#ë°˜íŒ”í‹°,#ì²˜ë¹„ë¼ì¸,#ì˜¤ë²„í•,#íŒŒë¥´í‹°ë©˜í† ,#ì˜¤ë²„í•ë°˜íŒ”}  \n",
      "4        19~24 ì—¬ì„±                                {\"#LMC ì“°ë¦¬ë² ì–´í‹°\",#LMC}  \n",
      "...           ...                                                ...  \n",
      "5364     19~24 ë‚¨ì„±                 {#ACHA,#í°ë§,#ë§ë°”ì§€ì²´ì¸,#ì•„ì°¨,#ì²´ì¸,#ë§,#ë§ê³ ë¦¬}  \n",
      "5365     19~24 ë‚¨ì„±  {#ì²´ì¸,\"#ì¨ì§€ì»¬ìŠ¤í‹¸ ë°”ì§€ì²´ì¸\",#ì¨ì§€ì»¬ìŠ¤í‹¸,#ì•„ì°¨,#ACHA,#ë ˆì´ì–´ë“œë°”ì§€ì²´ì¸,...  \n",
      "5366     19~24 ë‚¨ì„±        {#ë°´ë“œ,#FCMM,#ì†ëª©ë³´í˜¸ëŒ€,\"#ì†ëª© ë°´ë“œ\",#ì—í”„ì”¨ì— ì— ,#ìŠ¤í¬ì¸ ,#ì•„ëŒ€}  \n",
      "5367                     {\"#SAMO ONDOH\",#ì•…ì„¸ì‚¬ë¦¬,#ìŠ¤íŠ¸ë©,\"#ì„¸ì´ëª¨ ì˜¨ë„\",#ê°€ë°©ìŠ¤íŠ¸ë©}  \n",
      "5368                     {#ì•…ì„¸ì‚¬ë¦¬,\"#ì„¸ì´ëª¨ ì˜¨ë„\",#ìŠ¤íŠ¸ë©,#ê°€ë°©ìŠ¤íŠ¸ë©,\"#SAMO ONDOH\"}  \n",
      "\n",
      "[5369 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "from xlwings.utils import rgb_to_int\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "os.environ[\"NLS_LANG\"] = \".AL32UTF8\"\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://postgres:1111@172.0.2.93:5432/postgres')\n",
    "con = engine.connect()\n",
    "\n",
    "strSQL = \"\"\"\n",
    "        select * from db_mkt_musinsa_top20\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(strSQL, con)\n",
    "print(df)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       408000\n",
      "1       294000\n",
      "2       232000\n",
      "3       228000\n",
      "4       277000\n",
      "         ...  \n",
      "5364       200\n",
      "5365       200\n",
      "5366       400\n",
      "5367        77\n",
      "5368        53\n",
      "Name: pg_view, Length: 5369, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def char_to_int(x):\n",
    "    x = str(x)\n",
    "    y = x\n",
    "    try:\n",
    "        if 'ì²œ' in x:\n",
    "            if '.' in x:\n",
    "                y = int(str(x.replace('.', '')).replace('ì²œ', '')) * 100\n",
    "            else:\n",
    "                y = int(x.replace('ì²œ', '')) * 1000\n",
    "        elif 'ë§Œ' in x:\n",
    "            if '.' in x:\n",
    "                y = int(str(x.replace('.', '')).replace('ë§Œ', '')) * 1000\n",
    "            else:\n",
    "                y = int(x.replace('ë§Œ', '')) * 10000\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    return y\n",
    "\n",
    "df['pg_view'] = df['pg_view'].map(lambda item : char_to_int(item))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['pg_view'] = df['pg_view'].to_numeric\n",
    "\n",
    "print(df['pg_view'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "146"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cx_Oracle as co\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "os.environ[\"NLS_LANG\"] = \".AL32UTF8\"\n",
    "path = 'C://Users/kyujin/Desktop/PROCESS/code_ë””ìì¸ì‹¤_200721.xlsx'\n",
    "\n",
    "ds_select = pd.read_excel(path, sheet_name='CB', index_col=None)\n",
    "\n",
    "len(ds_select)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['name', 'code'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-b55c4c175255>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mpath1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'C://Users/kyujin/Desktop/PROCESS/code_ë””ìì¸ì‹¤_200721.xlsx'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mds_code\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_excel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msheet_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'Sheet2'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mds_sub\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mds_code\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'name'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'code'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mdf_sub\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mds_code\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mdf_sub\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kyujin\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2804\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2805\u001B[0m                 \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2806\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_listlike_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mraise_missing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2807\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2808\u001B[0m         \u001B[1;31m# take() does not accept boolean indexers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kyujin\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_get_listlike_indexer\u001B[1;34m(self, key, axis, raise_missing)\u001B[0m\n\u001B[0;32m   1551\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1552\u001B[0m         self._validate_read_indexer(\n\u001B[1;32m-> 1553\u001B[1;33m             \u001B[0mkeyarr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_axis_number\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mraise_missing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mraise_missing\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1554\u001B[0m         )\n\u001B[0;32m   1555\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mkeyarr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kyujin\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_validate_read_indexer\u001B[1;34m(self, key, indexer, axis, raise_missing)\u001B[0m\n\u001B[0;32m   1638\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mmissing\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1639\u001B[0m                 \u001B[0maxis_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_axis_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1640\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1641\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1642\u001B[0m             \u001B[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of [Index(['name', 'code'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "path1 = 'C://Users/kyujin/Desktop/PROCESS/code_ë””ìì¸ì‹¤_200721.xlsx'\n",
    "ds_code = pd.read_excel(path, sheet_name='Sheet2', index_col=None)\n",
    "ds_sub = ds_code[['name', 'code']]\n",
    "df_sub = ds_code.iloc[1:, 2:4]\n",
    "df_sub"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   name      code\n1                                  íŒ¨ì…˜ì¡í™”  50000001\n2                           íŒ¨ì…˜ì˜ë¥˜ > ì—¬ì„±ì˜ë¥˜  50000167\n3                      íŒ¨ì…˜ì˜ë¥˜ > ì—¬ì„±ì–¸ë”ì›¨ì–´/ì ì˜·  50000168\n4                           íŒ¨ì…˜ì˜ë¥˜ > ë‚¨ì„±ì˜ë¥˜  50000169\n5                      íŒ¨ì…˜ì˜ë¥˜ > ë‚¨ì„±ì–¸ë”ì›¨ì–´/ì ì˜·  50000170\n..                                  ...       ...\n497          ë©´ì„¸ì  > ì „ìì œí’ˆ > ê°€ì „ì œí’ˆ > ê¸°íƒ€ê°€ì „ì œí’ˆ  50003083\n498  ë©´ì„¸ì  > ì „ìì œí’ˆ > MP3/ì´ì–´í°/í—¤ë“œí° > MP3/PMP  50003084\n499     ë©´ì„¸ì  > ì „ìì œí’ˆ > MP3/ì´ì–´í°/í—¤ë“œí° > ì „ìì‚¬ì „  50003085\n500      ë©´ì„¸ì  > ì „ìì œí’ˆ > MP3/ì´ì–´í°/í—¤ë“œí° > ì´ì–´í°  50003086\n501      ë©´ì„¸ì  > ì „ìì œí’ˆ > MP3/ì´ì–´í°/í—¤ë“œí° > í—¤ë“œí°  50003087\n\n[501 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>íŒ¨ì…˜ì¡í™”</td>\n      <td>50000001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>íŒ¨ì…˜ì˜ë¥˜ &gt; ì—¬ì„±ì˜ë¥˜</td>\n      <td>50000167</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>íŒ¨ì…˜ì˜ë¥˜ &gt; ì—¬ì„±ì–¸ë”ì›¨ì–´/ì ì˜·</td>\n      <td>50000168</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>íŒ¨ì…˜ì˜ë¥˜ &gt; ë‚¨ì„±ì˜ë¥˜</td>\n      <td>50000169</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>íŒ¨ì…˜ì˜ë¥˜ &gt; ë‚¨ì„±ì–¸ë”ì›¨ì–´/ì ì˜·</td>\n      <td>50000170</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>ë©´ì„¸ì  &gt; ì „ìì œí’ˆ &gt; ê°€ì „ì œí’ˆ &gt; ê¸°íƒ€ê°€ì „ì œí’ˆ</td>\n      <td>50003083</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>ë©´ì„¸ì  &gt; ì „ìì œí’ˆ &gt; MP3/ì´ì–´í°/í—¤ë“œí° &gt; MP3/PMP</td>\n      <td>50003084</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>ë©´ì„¸ì  &gt; ì „ìì œí’ˆ &gt; MP3/ì´ì–´í°/í—¤ë“œí° &gt; ì „ìì‚¬ì „</td>\n      <td>50003085</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>ë©´ì„¸ì  &gt; ì „ìì œí’ˆ &gt; MP3/ì´ì–´í°/í—¤ë“œí° &gt; ì´ì–´í°</td>\n      <td>50003086</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>ë©´ì„¸ì  &gt; ì „ìì œí’ˆ &gt; MP3/ì´ì–´í°/í—¤ë“œí° &gt; í—¤ë“œí°</td>\n      <td>50003087</td>\n    </tr>\n  </tbody>\n</table>\n<p>501 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "os.environ[\"NLS_LANG\"] = \".AL32UTF8\"\n",
    "path = 'C://Users/kyujin/Desktop/PROCESS/code_ë””ìì¸ì‹¤_200721.xlsx'\n",
    "ds_select = pd.read_excel(path, sheet_name='CB', index_col=None, header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  view_count    author  \\\n",
      "0           0        5464     ì œë‹ˆìŠ¤íƒ€ì¼   \n",
      "1           2         315    íŒ¨ì…˜ì¸ì‚¬ì´íŠ¸   \n",
      "2           4        3859  ë§ˆê³ ì˜ íŒ¨ì…˜ë·°í‹°   \n",
      "3           6         540    íŒ¨ì…˜ì¸ì‚¬ì´íŠ¸   \n",
      "4           8         138    íŒ¨ì…˜ì¸ì‚¬ì´íŠ¸   \n",
      "\n",
      "                                            contents   issue_date  \\\n",
      "0  â–² â€˜ë©‹ì´ë€ ê²Œ í­ë°œí–ˆë‹¤â€™ ë°°ìš° ë¬¸ìˆ™, â€˜MLB ëª¨ë…¸ê·¸ë¨â€™ í›„ë¦¬ìŠ¤ ë¡±íŒ¨ë”© í™”ë³´ ê³µê°œ...  2019.10.23.   \n",
      "1  ì˜¤í”„ë‹ì‡¼ì—ì„œ ë„¤ ë‚¨ìê°€ ì°©ìš©í•œ ì•„ì´í…œì€ 'MLB'ì˜ í´ë˜ìŠ¤ê°€ ë‹¤ë¥¸ í´ë˜ì‹ ìŠ¤íƒ€ì¼ì˜ ...  2019.12.20.   \n",
      "2  ë§ˆì§€ë§‰ìœ¼ë¡œMLBí‚¤ì¦ˆ ëª¨ë…¸ê·¸ë¨ ì»¬ë ‰ì…˜ì´ì—ìš” :)ë‰´ìš• ì–‘í‚¤ìŠ¤ ë¡œê³ ë¥¼ëª¨ë˜í•˜ê²Œ ì¬í•´ì„í•´ê³ ê¸‰...  2019.08.29.   \n",
      "3  ê°•ì¡°í•œ MLB ëª¨ë…¸ê·¸ë¨ ì»¬ë ‰ì…˜ F&F(ëŒ€í‘œ ê¹€ì°½ìˆ˜)ì—ì„œ ì „ê°œí•˜ëŠ” ìŠ¤íŠ¸ë¦¬íŠ¸ ìºì£¼ì–¼ ë¸Œ...  2019.10.23.   \n",
      "4  ë³´ì•„í”Œë¦¬ìŠ¤ ì í¼ì— ëª¨ë…¸ê·¸ë¨ ìº¡ ì°©ìš© ê°ê°ì  ìŠ¤íŠ¸ë¦¬íŠ¸ë£© ì„ ë³´ì—¬ í™”ì œ MLBí‚¤ì¦ˆ â€˜ë©”ê°€...  2019.10.28.   \n",
      "\n",
      "                                          title  \\\n",
      "0  â€˜ë©‹ì´ë€ ê²Œ í­ë°œí–ˆë‹¤â€™ ë°°ìš° ë¬¸ìˆ™, â€˜MLB ëª¨ë…¸ê·¸ë¨â€™ í›„ë¦¬ìŠ¤ ë¡±íŒ¨ë”© í™”ë³´ ê³µê°œ   \n",
      "1                 MLB ëª¨ë…¸ê·¸ë¨ ì…ê³  â€˜íŒŒí‹°ì•ˆí•˜ë©´ ì§€ìƒë ¬â€™ ì›ƒìŒ ì„ ì‚¬   \n",
      "2              [êµ¬ì°Œí‚¤ì¦ˆë¶€í„° MLBí‚¤ì¦ˆê¹Œì§€] í‚¤ì¦ˆ ëª¨ë…¸ê·¸ë¨ ì•„ì´í…œ ëª¨ìŒâ™¥   \n",
      "3                         MLB ëª¨ë…¸ê·¸ë¨ â€œì˜ˆì•½ ì•ˆí•˜ë©´ ëª» ì‚¬â€   \n",
      "4                     MLBí‚¤ì¦ˆ â€˜ë©”ê°€ë² ì–´â€™ ë™ëŒ€ë¬¸ ì¼ëŒ€ ì´ìƒ‰ íˆ¬ì–´   \n",
      "\n",
      "                                                 url        date  \n",
      "0  https://m.post.naver.com/viewer/postView.nhn?v...  2020-08-12  \n",
      "1  https://m.post.naver.com/viewer/postView.nhn?v...  2020-08-12  \n",
      "2  https://m.post.naver.com/viewer/postView.nhn?v...  2020-08-12  \n",
      "3  https://m.post.naver.com/viewer/postView.nhn?v...  2020-08-12  \n",
      "4  https://m.post.naver.com/viewer/postView.nhn?v...  2020-08-12  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/kyujin/Desktop/PROCESS/MKT/viral_data/mlbëª¨ë…¸ê·¸ë¨_post_2020_08_12.csv')\n",
    "df['issue_date'] = pd.to_datetime(df['issue_date'], format='%Y-%m-%d', errors='ignore')\n",
    "print(df['issue_date'])\n",
    "\n",
    "#\n",
    "#\n",
    "# df['year'] = df['issue_date'].dt.year\n",
    "# df['week_num'] = df['issue_date'].dt.weekofyear\n",
    "# df['month'] = df['issue_date'].dt.month\n",
    "#\n",
    "# print(df[['issue_date','year','week_num']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        key  blog_cnt\n",
      "0   2018_18         1\n",
      "1    2018_2         1\n",
      "2   2018_41         1\n",
      "3   2018_42         1\n",
      "4   2018_51         1\n",
      "..      ...       ...\n",
      "68   2020_5         7\n",
      "69   2020_6         5\n",
      "70   2020_7         7\n",
      "71   2020_8        20\n",
      "72   2020_9        15\n",
      "\n",
      "[73 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['key'] = df[['year','week_num']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "grouped = df.groupby(df['key']).count()['url'].to_frame()\n",
    "grouped = grouped.reset_index()\n",
    "chnl = 'blog'\n",
    "grouped.columns = ['key', chnl + '_cnt']\n",
    "print(grouped)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title     issue_date  \\\n",
      "0                           ë¹…ë³¼ì²­í‚¤ëŠ” ë¹ˆí‹°ì§€ ì•„ë‹ˆë©´ ì‚¬ì§€ë§ˆ! and ì½”ë””?  2019. 11. 12.   \n",
      "1                                          MLB ë¹…ë³¼ì²­í‚¤ ë¦¬ë·°    2019. 2. 7.   \n",
      "2       ì–´ê¸€ë¦¬ìŠˆì¦ˆ ê°€ì„±ë¹„ ëíŒì™• MLB 'ë¹…ë³¼ì²­í‚¤' ì§ì ‘ ì‹ ì–´ë³´ê³  ì•Œë ¤ì£¼ëŠ” ì‹ ë°œ ë¦¬ë·° :D   2019. 4. 18.   \n",
      "3                          ì¸ì‹¸í…œ MLB ë¹…ë³¼ì²­í‚¤ ì–´ê¸€ë¦¬ìŠˆì¦ˆ ì €ë„ ì‚¬ë´¤ì–´ìš”!   2019. 4. 19.   \n",
      "4                         ìƒˆí•™ê¸° ë§ì´ (ì§‘ì—ì„œ ëŒ€ë¦¬ë§Œì¡±) ì‹ ë°œì†Œê°œí•˜ê¸° ğŸ˜­â¤ï¸   2020. 4. 27.   \n",
      "..                                                 ...            ...   \n",
      "413                                   8ì›”ì—” ì´ ì‹ ë°œ ì‚¬ì‹œë©´ ë©ë‹ˆë‹¤   2020. 7. 31.   \n",
      "414  ë‚˜ì´í‚¤ SB ë©í¬ ë¡œìš° x ë°´ ì—” ì œë¦¬ìŠ¤ ì²­í‚¤ ë©í‚¤ Ben & Jerry's Chu...   2020. 8. 10.   \n",
      "415  [NIKE] ë‚˜ì´í‚¤ SB ë©í¬ ë¡œìš° x ë°´ ì—” ì œë¦¬ìŠ¤ ì²­í‚¤ ë©í‚¤ Ben & Jerr...   2020. 8. 10.   \n",
      "416  [NIKE] ë‚˜ì´í‚¤ SB ë©í¬ ë¡œìš° x ë°´ ì—” ì œë¦¬ìŠ¤ ì²­í‚¤ ë©í‚¤ Ben & Jerr...   2020. 8. 11.   \n",
      "417  ë‚˜ì´í‚¤ SB ë©í¬ ë¡œìš° x ë°´ ì—” ì œë¦¬ìŠ¤ ì²­í‚¤ ë©í‚¤ Ben & Jerry's Chu...   2020. 8. 11.   \n",
      "\n",
      "    view_count               author  follower  \n",
      "0        43331                í•ë”ì‚¬ì´ì¦ˆ  254000.0  \n",
      "1        51953              ì™€ë””ì˜ ì‹ ë°œì¥  147000.0  \n",
      "2        29726                   ì •í™    1030.0  \n",
      "3        29941                 ìš”í”¼TV     807.0  \n",
      "4        18278                   ìˆ¨ì–‘   48600.0  \n",
      "..         ...                  ...       ...  \n",
      "413      12524              ì™€ë””ì˜ ì‹ ë°œì¥  147000.0  \n",
      "414          2      ì‹ ë°œë‚œë‹¤ ë¦¬ë·° ì˜ìƒ ëª¨ìŒ!!       NaN  \n",
      "415          1      ì‹ ë°œë‚œë‹¤ ë¦¬ë·° ì˜ìƒ ëª¨ìŒ!!       NaN  \n",
      "416          1  í•˜ì´ì•¤ë“œì‹ ë°œë‚˜ì´í‚¤ì´ì§€ì¡°ë˜1ì˜¤í”„í™”ì´íŠ¸       NaN  \n",
      "417         1íšŒ              ì‹ ë°œ_ì¸ì‚¬ì´ë“œ       NaN  \n",
      "\n",
      "[418 rows x 5 columns]\n",
      "Index(['title', 'issue_date', 'view_count', 'author', 'follower'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/kyujin/Desktop/PROCESS/MKT/viral_data/ë¹…ë³¼ì²­í‚¤_youtube.xlsx')\n",
    "df = df.iloc[:, 1:-1]\n",
    "df.rename(columns={'title':'title', 'post_date':'issue_date', 'view':'view_count', 'user':'author', 'follower':'follower'}, inplace=True)\n",
    "print(df)\n",
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2019-10-23\n",
      "1    2019-12-20\n",
      "2    2019-08-29\n",
      "3    2019-10-23\n",
      "4    2019-10-28\n",
      "5    2020-04-20\n",
      "6    2020-05-26\n",
      "7    2020-05-22\n",
      "8    2020-04-29\n",
      "9    2020-03-26\n",
      "10   2020-03-27\n",
      "11   2020-04-28\n",
      "12   2020-02-27\n",
      "13   2020-03-12\n",
      "14   2020-02-21\n",
      "15   2019-12-06\n",
      "16   2020-02-28\n",
      "17   2020-02-07\n",
      "18   2020-07-22\n",
      "19   2020-06-12\n",
      "20   2020-04-24\n",
      "21   2020-01-08\n",
      "22   2019-11-08\n",
      "23   2019-10-01\n",
      "24   2020-08-04\n",
      "25   2020-03-30\n",
      "26   2020-03-26\n",
      "27   2020-04-10\n",
      "28   2020-04-02\n",
      "29   2020-05-06\n",
      "30   2020-06-29\n",
      "31   2019-12-10\n",
      "32   2019-08-31\n",
      "33   2020-05-06\n",
      "34   2020-04-02\n",
      "35   2020-04-09\n",
      "36   2019-12-03\n",
      "37   2020-04-13\n",
      "38   2019-12-16\n",
      "39   2020-05-03\n",
      "Name: issue_date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/kyujin/Desktop/PROCESS/MKT/viral_data/mlbëª¨ë…¸ê·¸ë¨_post_2020_08_12.csv')\n",
    "df['issue_date'] = df['issue_date'].apply(lambda x : x[:-1])\n",
    "df['issue_date'] = pd.to_datetime(df['issue_date'], format='%Y-%m-%d')\n",
    "print(df['issue_date'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region      RF/ë„ë§¤          êµ­ë‚´           ë©´ì„¸         ì¤‘êµ­        í™ë§ˆëŒ€\n",
      "cls                                                             \n",
      "ë‹¹í•´      383308768  1708459260   2633374980  541782590  260961312\n",
      "ì „ë…„      974720000  2029680380  10129976300  242856656  524975264\n",
      "ì „ì£¼      491509888  1902917120   3413957630  889138110  273694016\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('C:/Users/kyujin/Desktop/test.xlsx', sheet_name='Sheet1', index=False)\n",
    "sum_df = df.groupby(['cls','region'])['sale_amt'].sum()\n",
    "sum_df = sum_df.unstack()\n",
    "print(sum_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region\n",
      "RF/ë„ë§¤     39.32501313197636%\n",
      "êµ­ë‚´        84.17380770069818%\n",
      "ë©´ì„¸        25.99586516308039%\n",
      "ì¤‘êµ­       223.08739604814454%\n",
      "í™ë§ˆëŒ€       49.70925868232908%\n",
      "Name: ì „ë…„ë¹„, dtype: object\n"
     ]
    }
   ],
   "source": [
    "t_df = sum_df.transpose()\n",
    "t_df['ì „ë…„ë¹„'] = t_df['ë‹¹í•´']/t_df['ì „ë…„']*100\n",
    "t_df['ì „ì£¼ë¹„'] = t_df['ë‹¹í•´']/t_df['ì „ì£¼']*100\n",
    "t_df['ì „ë…„ë¹„'] = t_df['ì „ë…„ë¹„'].apply(lambda x : str(x) + '%')\n",
    "print(t_df['ì „ë…„ë¹„'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_excel('C:/Users/kyujin/Desktop/test.xlsx', sheet_name='Sheet1', index=False)\n",
    "\n",
    "sum_df = df.groupby(['cls','region'])['sale_amt'].sum()\n",
    "sum_df = sum_df.unstack()\n",
    "\n",
    "df_tr = sum_df.transpose()\n",
    "df_tr['ì „ë…„ë¹„'] = [x / y * 100 if y != 0 else 0 for x, y in zip(df_tr['ë‹¹í•´'], df_tr['ì „ë…„'])]\n",
    "df_tr['ì „ì£¼ë¹„'] = [x / y * 100 if y != 0 else 0  for x, y in zip(df_tr['ë‹¹í•´'], df_tr['ì „ì£¼'])]\n",
    "format_mapping = {'ë‹¹í•´':'{:,.0f}', 'ì „ë…„':'{:,.0f}', 'ì „ì£¼':'{:,.0f}', 'ì „ì£¼ë¹„':'{:.2f}%', 'ì „ë…„ë¹„':'{:.2f}%'}\n",
    "for key, value in format_mapping.items():\n",
    "    df_tr[key] = df_tr[key].apply(value.format)\n",
    "\n",
    "df_re = df_tr.transpose().reset_index(drop=True)\n",
    "df_re = df_re.rename(index = {0 : 'ë‹¹í•´',1:'ì „ë…„',2:'ì „ì£¼', 3:'ì „ë…„ë¹„', 4:'ì „ì£¼ë¹„'})\n",
    "df_re.drop(['ì „ë…„', 'ì „ì£¼'], inplace=True)\n",
    "df_re = df_re[['êµ­ë‚´', 'RF/ë„ë§¤', 'ë©´ì„¸', 'ì¤‘êµ­', 'í™ë§ˆëŒ€']]\n",
    "print(df_re)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region             êµ­ë‚´        RF/ë„ë§¤             ë©´ì„¸           ì¤‘êµ­          í™ë§ˆëŒ€\n",
      "ë‹¹í•´      1,708,459,260  383,308,768  2,633,374,980  541,782,590  260,961,312\n",
      "ì „ë…„ë¹„            84.17%       39.33%         26.00%      223.09%       49.71%\n",
      "ì „ì£¼ë¹„            89.78%       77.99%         77.14%       60.93%        0.00%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('C:/Users/kyujin/Desktop/to_dataframe.xlsx')\n",
    "df.columns\n",
    "\n",
    "df_item = df[['brand', 'season', 'partcode']]\n",
    "cols = ['partcode', 'bg1',\n",
    "       'bg2', 'bg3', 'bg4', 'cp0', 'cp1', 'cp2', 'p3', 'cp4', 'cp5', 'cp6',\n",
    "       'cp7', 'cp8', 'cp9', 'cp10', 'cp11', 'cp12', 'cp13', 'cp14', 'cp15',\n",
    "       'sh1', 'sh2', 'sh3', 'sh4', 'sh5', 'sh6', 'sh7', 'outer1', 'outer2',\n",
    "       'outer3', 'outer4', 'outer5', 'outer6', 'outer7', 'outer8', 'outer9',\n",
    "       'top1', 'top2', 'top3', 'top4', 'top5', 'top6', 'top7', 'top8', 'top9',\n",
    "       'top10', 'top11', 'top12', 'top13']\n",
    "\n",
    "df_sub = df[cols].set_index('partcode')\n",
    "keyword_list = []\n",
    "for row in range(len(df_sub)):\n",
    "    s = df_sub.iloc[row].to_list()\n",
    "    cleaned_list = [x for x in s if str(x) != 'nan']\n",
    "    keyword_list.append(cleaned_list)\n",
    "df_sub = df_sub.assign(keyword = keyword_list)\n",
    "df_multi = df_sub[['keyword']]\n",
    "df_multi = df_multi.reset_index()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       partcode  keyword\n",
      "0     32CPWY011    MLBëª¨ì\n",
      "1     32CPWY011  MLBê²¨ìš¸ëª¨ì\n",
      "2     32CPYZ911    MLBëª¨ì\n",
      "3     32CPYZ911    MLBë³¼ìº¡\n",
      "4     32CPZA931    MLBëª¨ì\n",
      "...         ...      ...\n",
      "2629  31DJZ1961   MLBìˆíŒ¨ë”©\n",
      "2630  31DJS3961   MLBìˆíŒ¨ë”©\n",
      "2631  31DJS2961   MLBë¡±íŒ¨ë”©\n",
      "2632  31DJM2961   MLBìˆíŒ¨ë”©\n",
      "2633  31DJM1961   MLBë¡±íŒ¨ë”©\n",
      "\n",
      "[2634 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in df_multi.itertuples():\n",
    "    lst = i[2]\n",
    "    for col2 in lst:\n",
    "        data.append([i[1], col2])\n",
    "\n",
    "df_output = pd.DataFrame(data=data, columns=df_multi.columns)\n",
    "print(df_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     brand season   partcode  keyword\n",
      "0        M    20F  32CPWY011    MLBëª¨ì\n",
      "1        M    20F  32CPWY011  MLBê²¨ìš¸ëª¨ì\n",
      "2        M    19S  32CPYZ911    MLBëª¨ì\n",
      "3        M    19S  32CPYZ911    MLBë³¼ìº¡\n",
      "4        M    19S  32CPZA931    MLBëª¨ì\n",
      "...    ...    ...        ...      ...\n",
      "2629     M    19F  31DJZ1961   MLBìˆíŒ¨ë”©\n",
      "2630     M    19F  31DJS3961   MLBìˆíŒ¨ë”©\n",
      "2631     M    19F  31DJS2961   MLBë¡±íŒ¨ë”©\n",
      "2632     M    19F  31DJM2961   MLBìˆíŒ¨ë”©\n",
      "2633     M    19F  31DJM1961   MLBë¡±íŒ¨ë”©\n",
      "\n",
      "[2634 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_output = pd.DataFrame(data=data, columns=df_multi.columns)\n",
    "df_final = pd.merge(df_item, df_output, how='right', on='partcode')\n",
    "print(df_final)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_item = df[['brand', 'season', 'partcode']]\n",
    "cols = ['partcode', 'bg1',\n",
    "       'bg2', 'bg3', 'bg4', 'cp0', 'cp1', 'cp2', 'p3', 'cp4', 'cp5', 'cp6',\n",
    "       'cp7', 'cp8', 'cp9', 'cp10', 'cp11', 'cp12', 'cp13', 'cp14', 'cp15',\n",
    "       'sh1', 'sh2', 'sh3', 'sh4', 'sh5', 'sh6', 'sh7', 'outer1', 'outer2',\n",
    "       'outer3', 'outer4', 'outer5', 'outer6', 'outer7', 'outer8', 'outer9',\n",
    "       'top1', 'top2', 'top3', 'top4', 'top5', 'top6', 'top7', 'top8', 'top9',\n",
    "       'top10', 'top11', 'top12', 'top13']\n",
    "\n",
    "df_sub = df[cols].set_index('partcode')\n",
    "df_sub['keywords'] = ''\n",
    "keyword_list = []\n",
    "for row in range(len(df_sub)):\n",
    "    s = df_sub.iloc[row].to_list()\n",
    "    cleaned_list = [x for x in s if str(x) != 'nan']\n",
    "    striped_list = [x.replace(' ', '') for x in cleaned_list if x]\n",
    "    keywords = '#'.join(striped_list)\n",
    "    keyword_list.append(keywords)\n",
    "\n",
    "df = pd.DataFrame(keyword_list, columns=['keywords'])\n",
    "df_new = pd.concat([df_item, df], axis=1)\n",
    "print(df_new.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}